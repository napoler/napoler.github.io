---
layout: post
comments: 1
title:  2021-06-09 记事
categories: Default
tags: Default
date: 2021-06-09 10:10
---

 2021-06-09 记事



### Save/Load `state_dict` 权重加载保存

**Save:**
```
torch.save(model.state\_dict(), PATH)
```

**Load:**
```
model \= TheModelClass(\*args, \*\*kwargs)
model.load\_state\_dict(torch.load(PATH))
model.eval()
```


## pytorch-lightning 中**hp_metric**使用
https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html
hp_metric作为调参的指标值，需要自己指定不然无意义。

If you want to track a metric in the tensorboard hparams tab, log scalars to the key `hp_metric`. If tracking multiple metrics, initialize `TensorBoardLogger` with `default_hp_metric=False` and call `log_hyperparams` only once with your metric keys and initial values. Subsequent updates can simply be logged to the metric keys. Refer to the following for examples on how to setup proper hyperparams metrics tracking within [LightningModule](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html).

\# Using default\_hp\_metric
def validation\_step(self, batch, batch\_idx):
    self.log("hp\_metric", some\_scalar)

\# Using custom or multiple metrics (default\_hp\_metric=False)
def on\_train\_start(self):
    self.logger.log\_hyperparams(self.hparams, {"hp/metric\_1": 0, "hp/metric\_2": 0})

def validation\_step(self, batch, batch\_idx):
    self.log("hp/metric\_1", some\_scalar\_1)
    self.log("hp/metric\_2", some\_scalar\_2)

![Copy to clipboard](https://pytorch-lightning.readthedocs.io/en/stable/_static/copy-button.svg)

In the example, using hp/ as a prefix allows for the metrics to be grouped under “hp” in the tensorboard scalar tab where you can collapse them.
